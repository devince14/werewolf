# å¼ºåŒ–å­¦ä¹ æ¨¡å‹ä¸Šä¼ ä½¿ç”¨æŒ‡å—

## ğŸ¯ æ¦‚è¿°

æœ¬å¹³å°æœªæ¥å°†æ”¯æŒä¸Šä¼ è®­ç»ƒå¥½çš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼Œè®©æ‚¨çš„æ™ºèƒ½ä½“ä½¿ç”¨è®­ç»ƒå¥½çš„ç­–ç•¥è¿›è¡Œæ¸¸æˆã€‚
ä½†æ˜¯ç›®å‰ï¼Œæ‚¨å¯ä»¥åœ¨æºç ä¸­è¿›è¡Œä¿®æ”¹ä¸Šä¼ ã€‚
å…·ä½“æ–¹æ³•æ˜¯ï¼š
åœ¨competition_templateæ–‡ä»¶å¤¹ä¸­ï¼Œä¸Šä¼ è®­ç»ƒä»£ç åŠæ¨¡å‹ï¼Œè¿è¡ŒPythonæŒ‡ä»¤ï¼Œè¿›è¡Œè¯„ä¼°å¾—åˆ†ã€‚ä½¿ç”¨æ–¹æ³•ä¾‹å¦‚ä¸‹ï¼š
python evaluate_submission.py agents_user.random_agent.UserAgent --games 1000

## ğŸ“ æ”¯æŒçš„æ¨¡å‹æ ¼å¼

- **`.pkl`** - Python pickleæ ¼å¼ï¼ˆsklearnã€è‡ªå®šä¹‰æ¨¡å‹ç­‰ï¼‰
- **`.pth`** - PyTorchæ¨¡å‹æ–‡ä»¶
- **`.pt`** - PyTorchæ¨¡å‹æ–‡ä»¶ï¼ˆç®€åŒ–æ‰©å±•åï¼‰
- **`.h5`** - Keras/TensorFlowæ¨¡å‹æ–‡ä»¶
- **`.model`** - è‡ªå®šä¹‰æ¨¡å‹æ ¼å¼ï¼ˆä½¿ç”¨joblibï¼‰
- **`.weights`** - æƒé‡æ–‡ä»¶

## ğŸš€ ä½¿ç”¨æ­¥éª¤

### 1. ä¸Šä¼ æ¨¡å‹æ–‡ä»¶

1. ç™»å½•å¹³å°
2. åœ¨ä¸ªäººèµ„æ–™é¡µé¢æ‰¾åˆ°"æ¨¡å‹ç®¡ç†"éƒ¨åˆ†
3. ç‚¹å‡»"ä¸Šä¼ æ¨¡å‹æ–‡ä»¶"
4. é€‰æ‹©æ‚¨çš„æ¨¡å‹æ–‡ä»¶ï¼ˆæ”¯æŒæ ¼å¼è§ä¸Šï¼‰
5. æ–‡ä»¶å¤§å°é™åˆ¶ï¼š50MB

### 2. ä½¿ç”¨å¼ºåŒ–å­¦ä¹ æ¨¡æ¿

åœ¨ä»£ç ç¼–è¾‘å™¨ä¸­ï¼Œä½¿ç”¨ä»¥ä¸‹æ¨¡æ¿ï¼š

```python
import numpy as np
import os
import pickle
import torch
import joblib
from werewolf_env.werewolf_env import WerewolfEnv, Role, TalkType

class UserAgent:
    def __init__(self, agent_id: int, num_agents: int, role: Role):
        self.agent_id = agent_id
        self.num_agents = num_agents
        self.role = role
        
        # æ¨¡å‹ç›¸å…³
        self.model = None
        self.model_loaded = False
        
        # å°è¯•åŠ è½½æ¨¡å‹
        self._load_model()
        
    def _load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        try:
            # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶
            model_dir = os.path.join(os.path.dirname(__file__), '..', 'models')
            if not os.path.exists(model_dir):
                print("æ¨¡å‹ç›®å½•ä¸å­˜åœ¨")
                return
            
            # æŸ¥æ‰¾å½“å‰ç”¨æˆ·çš„æ¨¡å‹æ–‡ä»¶
            user_models = []
            for filename in os.listdir(model_dir):
                if filename.startswith(f'user_{self.agent_id}_') and \
                   filename.endswith(('.pkl', '.pth', '.h5', '.pt', '.model', '.weights')):
                    user_models.append(filename)
            
            if not user_models:
                print("æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶")
                return
            
            # ä½¿ç”¨æœ€æ–°çš„æ¨¡å‹æ–‡ä»¶
            latest_model = sorted(user_models)[-1]
            model_path = os.path.join(model_dir, latest_model)
            
            print(f"å°è¯•åŠ è½½æ¨¡å‹: {latest_model}")
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹åŠ è½½æ¨¡å‹
            if latest_model.endswith('.pkl'):
                with open(model_path, 'rb') as f:
                    self.model = pickle.load(f)
                    
            elif latest_model.endswith('.pth') or latest_model.endswith('.pt'):
                # PyTorchæ¨¡å‹
                self.model = torch.load(model_path, map_location='cpu')
                self.model.eval()
                
            elif latest_model.endswith('.h5'):
                # Kerasæ¨¡å‹
                import tensorflow as tf
                self.model = tf.keras.models.load_model(model_path)
                
            elif latest_model.endswith('.model'):
                # è‡ªå®šä¹‰æ¨¡å‹æ ¼å¼
                with open(model_path, 'rb') as f:
                    self.model = joblib.load(f)
                    
            elif latest_model.endswith('.weights'):
                # æƒé‡æ–‡ä»¶
                with open(model_path, 'rb') as f:
                    self.model = pickle.load(f)
            
            self.model_loaded = True
            print(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {latest_model}")
            
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None
            self.model_loaded = False
    
    def _extract_state_features(self, env):
        """æå–ç¯å¢ƒçŠ¶æ€ç‰¹å¾"""
        features = []
        
        # åŸºæœ¬ä¿¡æ¯
        features.extend([
            self.agent_id,
            self.num_agents,
            int(self.role == Role.WOLF),
            int(self.role == Role.SEER),
            int(self.role == Role.VILLAGER),
            int(env.stage == "talk"),
            int(env.stage == "vote"),
            int(env.stage == "night")
        ])
        
        # å­˜æ´»çŠ¶æ€
        for i in range(env.N):
            features.append(int(env.alive[i]))
        
        # æ¸¸æˆå†å²ï¼ˆç®€åŒ–ç‰ˆï¼‰
        if hasattr(env, 'talk_history') and env.talk_history:
            recent_talks = env.talk_history[-5:]  # æœ€è¿‘5è½®å‘è¨€
            for talk in recent_talks:
                features.extend([
                    talk.get('speaker', 0),
                    talk.get('talk_type', 0),
                    talk.get('target', env.N)
                ])
        else:
            # å¡«å……ç©ºçš„å†å²
            features.extend([0, 0, env.N] * 5)
        
        return np.array(features, dtype=np.float32)
    
    def _get_action_from_model(self, state_features):
        """ä»æ¨¡å‹è·å–è¡ŒåŠ¨"""
        if not self.model_loaded or self.model is None:
            return None
        
        try:
            # æ ¹æ®æ¨¡å‹ç±»å‹è¿›è¡Œæ¨ç†
            if hasattr(self.model, 'predict'):
                # sklearnæˆ–å…¶ä»–predictæ¥å£
                action = self.model.predict([state_features])[0]
            elif hasattr(self.model, '__call__'):
                # PyTorchæˆ–å…¶ä»–å¯è°ƒç”¨æ¨¡å‹
                if hasattr(self.model, 'eval'):
                    self.model.eval()
                with torch.no_grad():
                    action = self.model(torch.tensor(state_features).unsqueeze(0))
                    action = action.cpu().numpy()[0]
            else:
                # è‡ªå®šä¹‰æ¨¡å‹
                action = self.model(state_features)
            
            return action
            
        except Exception as e:
            print(f"æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
            return None
    
    def _action_to_env_action(self, model_action, env):
        """å°†æ¨¡å‹è¾“å‡ºè½¬æ¢ä¸ºç¯å¢ƒè¡ŒåŠ¨"""
        if model_action is None:
            return self._default_action(env)
        
        try:
            # æ ¹æ®å½“å‰é˜¶æ®µå¤„ç†è¡ŒåŠ¨
            if env.stage == "talk":
                # talké˜¶æ®µ: [claim_seer, talk_type, target]
                claim_seer = int(model_action[0] > 0.5) if len(model_action) > 0 else 0
                talk_type = int(model_action[1]) if len(model_action) > 1 else TalkType.CLAIM_GOOD
                target = int(model_action[2]) if len(model_action) > 2 else env.N
                
                # ç¡®ä¿å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…
                talk_type = max(0, min(talk_type, len(TalkType) - 1))
                target = max(0, min(target, env.N))
                
                return np.array([claim_seer, talk_type, target])
                
            elif env.stage == "vote":
                # voteé˜¶æ®µ: [target]
                target = int(model_action[0]) if len(model_action) > 0 else env.N
                target = max(0, min(target, env.N))
                return np.array([target])
                
            elif env.stage == "night":
                # nighté˜¶æ®µ: [target]
                target = int(model_action[0]) if len(model_action) > 0 else env.N
                target = max(0, min(target, env.N))
                return np.array([target])
                
            else:
                return self._default_action(env)
                
        except Exception as e:
            print(f"è¡ŒåŠ¨è½¬æ¢å¤±è´¥: {e}")
            return self._default_action(env)
    
    def _default_action(self, env):
        """é»˜è®¤è¡ŒåŠ¨ç­–ç•¥ï¼ˆæ¨¡å‹å¤±è´¥æ—¶çš„å¤‡ç”¨ç­–ç•¥ï¼‰"""
        if env.stage == "talk":
            return np.array([0, TalkType.CLAIM_GOOD, env.N])
        elif env.stage == "vote":
            alive_players = [i for i in range(env.N) if env.alive[i] and i != self.agent_id]
            if alive_players:
                return np.array([alive_players[0]])
            return np.array([env.N])
        elif env.stage == "night":
            alive_players = [i for i in range(env.N) if env.alive[i] and i != self.agent_id]
            if alive_players:
                return np.array([alive_players[0]])
            return np.array([env.N])
        else:
            return np.array([env.N])
    
    def act(self, env):
        """ä¸»è¦è¡ŒåŠ¨æ–¹æ³•"""
        # æå–çŠ¶æ€ç‰¹å¾
        state_features = self._extract_state_features(env)
        
        # ä»æ¨¡å‹è·å–è¡ŒåŠ¨
        model_action = self._get_action_from_model(state_features)
        
        # è½¬æ¢ä¸ºç¯å¢ƒè¡ŒåŠ¨
        action = self._action_to_env_action(model_action, env)
        
        return action
```

### 3. æäº¤è¯„æµ‹

1. ç¡®ä¿å·²ä¸Šä¼ æ¨¡å‹æ–‡ä»¶
2. ä½¿ç”¨ä¸Šè¿°æ¨¡æ¿ç¼–å†™ä»£ç 
3. ç‚¹å‡»"æäº¤è¯„æµ‹"
4. ç³»ç»Ÿä¼šè‡ªåŠ¨åŠ è½½æ‚¨çš„æ¨¡å‹å¹¶è¿›è¡Œè¯„æµ‹

## ğŸ”§ æ¨¡å‹è¦æ±‚

### è¾“å…¥æ ¼å¼
æ¨¡å‹åº”è¯¥æ¥å—ä¸€ä¸ªç‰¹å¾å‘é‡ä½œä¸ºè¾“å…¥ï¼ŒåŒ…å«ï¼š
- åŸºæœ¬ä¿¡æ¯ï¼ˆ8ä¸ªç‰¹å¾ï¼‰
- å­˜æ´»çŠ¶æ€ï¼ˆ5ä¸ªç‰¹å¾ï¼‰
- æ¸¸æˆå†å²ï¼ˆ15ä¸ªç‰¹å¾ï¼‰
- æ€»è®¡28ä¸ªç‰¹å¾

### è¾“å‡ºæ ¼å¼
æ¨¡å‹åº”è¯¥è¾“å‡ºä¸€ä¸ªè¡ŒåŠ¨å‘é‡ï¼š
- **talké˜¶æ®µ**: [claim_seer, talk_type, target]
- **voteé˜¶æ®µ**: [target]
- **nighté˜¶æ®µ**: [target]

## ğŸ“Š ç‰¹å¾è¯´æ˜

### åŸºæœ¬ä¿¡æ¯ (8ä¸ªç‰¹å¾)
- `agent_id`: è‡ªå·±çš„ç¼–å·
- `num_agents`: æ€»ç©å®¶æ•°
- `is_wolf`: æ˜¯å¦ä¸ºç‹¼äºº
- `is_seer`: æ˜¯å¦ä¸ºé¢„è¨€å®¶
- `is_villager`: æ˜¯å¦ä¸ºæ‘æ°‘
- `is_talk_stage`: æ˜¯å¦ä¸ºå‘è¨€é˜¶æ®µ
- `is_vote_stage`: æ˜¯å¦ä¸ºæŠ•ç¥¨é˜¶æ®µ
- `is_night_stage`: æ˜¯å¦ä¸ºå¤œæ™šé˜¶æ®µ

### å­˜æ´»çŠ¶æ€ (5ä¸ªç‰¹å¾)
- æ¯ä¸ªç©å®¶çš„å­˜æ´»çŠ¶æ€ï¼ˆ0æˆ–1ï¼‰

### æ¸¸æˆå†å² (15ä¸ªç‰¹å¾)
- æœ€è¿‘5è½®å‘è¨€çš„ä¿¡æ¯
- æ¯è½®åŒ…å«ï¼šå‘è¨€è€…ã€å‘è¨€ç±»å‹ã€ç›®æ ‡

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ¨¡å‹å…¼å®¹æ€§**
   - ç¡®ä¿æ¨¡å‹èƒ½åœ¨CPUä¸Šè¿è¡Œ
   - PyTorchæ¨¡å‹ä¼šè‡ªåŠ¨è½¬æ¢ä¸ºCPUæ¨¡å¼
   - å¤§å‹æ¨¡å‹å¯èƒ½å½±å“è¯„æµ‹é€Ÿåº¦

2. **æ–‡ä»¶å¤§å°**
   - æ¨¡å‹æ–‡ä»¶é™åˆ¶50MB
   - å»ºè®®å‹ç¼©æ¨¡å‹æˆ–ä½¿ç”¨é‡åŒ–æŠ€æœ¯

3. **é”™è¯¯å¤„ç†**
   - å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä¼šä½¿ç”¨é»˜è®¤ç­–ç•¥
   - æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºäº†è§£é”™è¯¯ä¿¡æ¯

4. **ä¾èµ–åŒ…**
   - ç¡®ä¿å®‰è£…äº†ç›¸å…³ä¾èµ–ï¼štorch, tensorflow, scikit-learn, joblib
   - æŸäº›æ¨¡å‹å¯èƒ½éœ€è¦ç‰¹å®šç‰ˆæœ¬çš„ä¾èµ–

## ğŸ® ç¤ºä¾‹

### ç®€å•çš„sklearnæ¨¡å‹
```python
# è®­ç»ƒæ—¶
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier()
model.fit(X_train, y_train)

# ä¿å­˜æ¨¡å‹
import pickle
with open('my_model.pkl', 'wb') as f:
    pickle.dump(model, f)
```

### PyTorchæ¨¡å‹
```python
# è®­ç»ƒæ—¶
import torch
model = MyNeuralNetwork()
# ... è®­ç»ƒè¿‡ç¨‹ ...
torch.save(model, 'my_model.pth')
```

## ğŸš€ æœ€ä½³å®è·µ

1. **æ¨¡å‹ä¼˜åŒ–**
   - ä½¿ç”¨æ¨¡å‹å‹ç¼©æŠ€æœ¯å‡å°æ–‡ä»¶å¤§å°
   - ç¡®ä¿æ¨¡å‹æ¨ç†é€Ÿåº¦å¿«
   - æµ‹è¯•æ¨¡å‹åœ¨ä¸åŒåœºæ™¯ä¸‹çš„è¡¨ç°

2. **ç‰¹å¾å·¥ç¨‹**
   - æ ¹æ®æ¸¸æˆç‰¹ç‚¹è®¾è®¡åˆé€‚çš„ç‰¹å¾
   - è€ƒè™‘æ·»åŠ æ›´å¤šæ¸¸æˆçŠ¶æ€ä¿¡æ¯
   - å®éªŒä¸åŒçš„ç‰¹å¾ç»„åˆ

3. **è®­ç»ƒç­–ç•¥**
   - ä½¿ç”¨è‡ªå¯¹å¼ˆè®­ç»ƒ
   - å¹³è¡¡æ¢ç´¢å’Œåˆ©ç”¨
   - å®šæœŸæ›´æ–°æ¨¡å‹

## ğŸ” æµ‹è¯•åŠŸèƒ½

å¹³å°æä¾›äº†æµ‹è¯•è„šæœ¬æ¥éªŒè¯å¼ºåŒ–å­¦ä¹ åŠŸèƒ½ï¼š

```bash
python test_rl_agent.py
```

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
2. æµ‹è¯•æ¨¡å‹åŠ è½½åŠŸèƒ½
3. æµ‹è¯•RLæ™ºèƒ½ä½“çš„åŸºæœ¬åŠŸèƒ½

## ğŸ“ å¸¸è§é—®é¢˜

### Q: æ¨¡å‹åŠ è½½å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
A: æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
- æ¨¡å‹æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®
- æ–‡ä»¶æ˜¯å¦æŸå
- æ˜¯å¦å®‰è£…äº†ç›¸åº”çš„ä¾èµ–åŒ…

### Q: æ¨¡å‹æ¨ç†é€Ÿåº¦æ…¢æ€ä¹ˆåŠï¼Ÿ
A: å¯ä»¥å°è¯•ï¼š
- ä½¿ç”¨æ¨¡å‹å‹ç¼©æŠ€æœ¯
- å‡å°‘æ¨¡å‹å¤æ‚åº¦
- ä½¿ç”¨æ›´å¿«çš„æ¨ç†æ¡†æ¶

### Q: å¦‚ä½•è°ƒè¯•æ¨¡å‹ï¼Ÿ
A: åœ¨ä»£ç ä¸­æ·»åŠ printè¯­å¥æ¥æŸ¥çœ‹ï¼š
- æ¨¡å‹åŠ è½½çŠ¶æ€
- ç‰¹å¾æå–ç»“æœ
- æ¨¡å‹è¾“å‡ºç»“æœ

ç¥æ‚¨è®­ç»ƒå‡ºå¼ºå¤§çš„ç‹¼äººæ€æ™ºèƒ½ä½“ï¼ğŸ¯ 